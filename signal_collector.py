"""
signal_collector.py - å—ä¿¡ãƒãƒƒãƒ•ã‚¡ï¼ˆ500msåŽé›†çª“ï¼‰
AI Trading System v2.0

åŒä¸€è¶³ã®ã‚·ã‚°ãƒŠãƒ«ãŒæ•°ç™¾mså·®ã§å±ŠããŸã‚ã€500msãƒãƒƒãƒ•ã‚¡ã§ã¾ã¨ã‚ã¦å‡¦ç†ã™ã‚‹ã€‚
"""

import logging
import threading
from datetime import datetime, timezone
from config import SYSTEM_CONFIG

logger = logging.getLogger(__name__)

WINDOW_MS       = SYSTEM_CONFIG["collection_window_ms"]   # 500ms
MAX_BUFFER_SIZE = SYSTEM_CONFIG.get("signal_buffer_size", 50) * 4  # å·®ã—æˆ»ã—ãƒ«ãƒ¼ãƒ—ã«ã‚ˆã‚‹ç„¡é™è“„ç©é˜²æ­¢ã®ä¸Šé™ï¼ˆä¸Šé™è¶…éŽã¯å±¥æ­´ã‚’ç ´æ£„ï¼‰


class SignalCollector:
    """500msã®åŽé›†çª“ã§ã‚·ã‚°ãƒŠãƒ«ã‚’ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã™ã‚‹"""

    def __init__(self, on_batch_ready):
        """
        on_batch_ready: ãƒãƒƒãƒãŒç¢ºå®šã—ãŸã¨ãã«å‘¼ã°ã‚Œã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        on_batch_ready(batch: list[dict]) -> None
        """
        self._on_batch_ready = on_batch_ready
        self._buffer: list[dict] = []
        self._lock   = threading.Lock()
        self._timer: threading.Timer | None = None

    def receive(self, signal: dict) -> None:
        """ã‚·ã‚°ãƒŠãƒ«ã‚’å—ä¿¡ã—ã¦ãƒãƒƒãƒ•ã‚¡ã«ç©ã‚€ã€‚ã‚¿ã‚¤ãƒžãƒ¼ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹"""
        with self._lock:
            self._buffer.append(signal)
            logger.debug("ðŸŸ¡ ãƒãƒƒãƒ•ã‚¡è¿½åŠ : source=%s event=%s direction=%s",
                         signal.get("source"), signal.get("event"),
                         signal.get("direction"))
            self._reset_timer()

    def _reset_timer(self) -> None:
        """æ—¢å­˜ã‚¿ã‚¤ãƒžãƒ¼ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¦æ–°ã—ã„ã‚¿ã‚¤ãƒžãƒ¼ã‚’ã‚»ãƒƒãƒˆ"""
        if self._timer is not None:
            self._timer.cancel()
        self._timer = threading.Timer(
            WINDOW_MS / 1000.0,
            self._flush,
        )
        self._timer.daemon = True
        self._timer.start()

    def _flush(self) -> None:
        """ã‚¿ã‚¤ãƒžãƒ¼æº€äº†æ™‚ã«ãƒãƒƒãƒ•ã‚¡ã‚’ç¢ºå®šã—ã¦å‡¦ç†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å‘¼ã¶"""
        with self._lock:
            if not self._buffer:
                return
            batch = self._buffer[:]
            self._buffer.clear()
            self._timer = None

        logger.info("ðŸ“¦ ãƒãƒƒãƒç¢ºå®š %dä»¶ â†’ å‡¦ç†é–‹å§‹", len(batch))
        try:
            self._on_batch_ready(batch)
        except Exception as e:
            logger.error("ãƒãƒƒãƒå‡¦ç†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¾‹å¤–: %s", e, exc_info=True)
            # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤±æ•—æ™‚ã¯ãƒãƒƒãƒ•ã‚¡ã«å·®ã—æˆ»ã™ï¼ˆã‚·ã‚°ãƒŠãƒ«æ¶ˆæ»…é˜²æ­¢ï¼‰
            with self._lock:
                merged = batch + self._buffer  # batchã‚’å…ˆé ­ã«æŒ¿å…¥ã—ã¦é †åºä¿æŒ
                if len(merged) > MAX_BUFFER_SIZE:
                    excess = len(merged) - MAX_BUFFER_SIZE
                    merged = merged[:MAX_BUFFER_SIZE]
                    logger.error(
                        "ðŸš¨ ãƒãƒƒãƒ•ã‚¡ä¸Šé™(%d)è¶…éŽã€‚å¤ã„ã‚·ã‚°ãƒŠãƒ« %dä»¶ã‚’ç ´æ£„ã—ã¾ã—ãŸï¼ˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æ’å¸¸å¤±æ•—ã®å¯èƒ½æ€§ï¼‰",
                        MAX_BUFFER_SIZE, excess,
                    )
                self._buffer = merged
                logger.warning("âš ï¸ ãƒãƒƒãƒ•ã‚¡ã« %dä»¶ã‚’å·®ã—æˆ»ã—ã¾ã—ãŸï¼ˆãƒªã‚«ãƒãƒªãƒ¼ï¼‰", len(merged))

    # ãƒ‡ãƒãƒƒã‚°ãƒ»ãƒ†ã‚¹ãƒˆç”¨
    def flush_now(self) -> None:
        with self._lock:
            if self._timer:
                self._timer.cancel()
                self._timer = None
        self._flush()
